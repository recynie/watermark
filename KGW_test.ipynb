{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from watermark.auto_watermark import AutoWatermark\n",
    "from utils.transformers_config import TransformersConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_config = TransformersConfig(\n",
    "    model=AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-0.5B').to(device),\n",
    "    tokenizer=AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B'),\n",
    "    # vocab_size=50272,\n",
    "    device=device,\n",
    "    # max_new_tokens=200,\n",
    "    # min_length=204,\n",
    "    # do_sample=True,\n",
    "    # no_repeat_ngram_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Load watermark algorithm\n",
    "from watermark.base import BaseWatermark\n",
    "from watermark.kgw import KGW\n",
    "myWatermark:BaseWatermark = AutoWatermark.load(\n",
    "    'KGW', \n",
    "    algorithm_config='config/KGW.json',\n",
    "    transformers_config=transformers_config\n",
    ")\n",
    "myWatermark:KGW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "prompt = \\\n",
    "'''Give me a short introduction to large language model.\n",
    "'''\n",
    "\n",
    "# Generate and detect\n",
    "watermarked_text = myWatermark.generate_watermarked_text(prompt)\n",
    "wm_detect_result = myWatermark.detect_watermark(watermarked_text)\n",
    "unwatermarked_text = myWatermark.generate_unwatermarked_text(prompt)\n",
    "unwm_detect_result = myWatermark.detect_watermark(unwatermarked_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a short introduction to large language model.\n",
      "A large language model, also known as a deep learning model, is a type of machine learning model that uses deep neural networks to process and analyze large amounts of data. These models are trained on large amounts of data, such as the internet or text, and can learn complex language patterns and structures from this data. Large language models are used in various applications, such as chatbots, language translation, and text generation.\n",
      "{'is_watermarked': True, 'score': 5.081063304179084}\n"
     ]
    }
   ],
   "source": [
    "print(watermarked_text)\n",
    "print(wm_detect_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a short introduction to large language model.\n",
      "A large language model (LLM) is a type of artificial intelligence (AI) that can generate human-like text based on a large amount of data. These models are designed to understand and generate text based on the context of the input, and they are often used for tasks such as language translation, text summarization, and chatbots.\n",
      "{'is_watermarked': False, 'score': 0.3418817293789138}\n"
     ]
    }
   ],
   "source": [
    "print(unwatermarked_text)\n",
    "print(unwm_detect_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KGW_test.output.txt','w') as f:\n",
    "    l=[watermarked_text,wm_detect_result,unwatermarked_text,unwm_detect_result]\n",
    "    l=[str(item) for item in l]\n",
    "    f.write('\\n'.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from visualize.font_settings import FontSettings\n",
    "from watermark.auto_watermark import AutoWatermark\n",
    "from utils.transformers_config import TransformersConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from visualize.visualizer import DiscreteVisualizer\n",
    "from visualize.legend_settings import DiscreteLegendSettings\n",
    "from visualize.page_layout_settings import PageLayoutSettings\n",
    "from visualize.color_scheme import ColorSchemeForDiscreteVisualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get data for visualization\n",
    "watermarked_data = myWatermark.get_data_for_visualization(watermarked_text)\n",
    "unwatermarked_data = myWatermark.get_data_for_visualization(unwatermarked_text)\n",
    "\n",
    "# Init visualizer\n",
    "visualizer = DiscreteVisualizer(color_scheme=ColorSchemeForDiscreteVisualization(),\n",
    "                                font_settings=FontSettings(), \n",
    "                                page_layout_settings=PageLayoutSettings(),\n",
    "                                legend_settings=DiscreteLegendSettings())\n",
    "# Visualize\n",
    "watermarked_img = visualizer.visualize(data=watermarked_data, \n",
    "                                       show_text=True, \n",
    "                                       visualize_weight=True, \n",
    "                                       display_legend=True)\n",
    "\n",
    "unwatermarked_img = visualizer.visualize(data=unwatermarked_data,\n",
    "                                         show_text=True, \n",
    "                                         visualize_weight=True, \n",
    "                                         display_legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save\n",
    "watermarked_img.save(\"viz/KGW_watermarked.png\")\n",
    "unwatermarked_img.save(\"viz/KGW_unwatermarked.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
